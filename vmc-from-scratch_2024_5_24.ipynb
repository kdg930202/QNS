{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import netket\n",
    "from flax.core.scope import CollectionFilter\n",
    "from netket.utils.types import PyTree\n",
    "from netket.operator import Squared\n",
    "from functools import partial, lru_cache\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax.core.scope import CollectionFilter, DenyList  # noqa: F401\n",
    "\n",
    "import netket as nk\n",
    "from netket import jax as nkjax\n",
    "from netket.operator import DiscreteOperator, Squared\n",
    "from netket.stats import Stats\n",
    "from netket.utils.types import PyTree\n",
    "from netket.utils.dispatch import dispatch\n",
    "\n",
    "# from nektet.vqs import _ex\n",
    "from netket.vqs import expect_and_grad, expect_and_forces\n",
    "from netket.vqs.mc.common import force_to_grad, get_local_kernel, get_local_kernel_arguments\n",
    "from netket.stats import Stats\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from netket.operator.spin import sigmax, sigmay,sigmaz\n",
    "from netket.stats import Stats, statistics\n",
    "\n",
    "from functools import partial\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax.core.scope import CollectionFilter, DenyList  # noqa: F401\n",
    "\n",
    "from netket import jax as nkjax\n",
    "from netket import config\n",
    "from netket.stats import Stats\n",
    "from netket.utils import mpi, dispatch\n",
    "from netket.utils.types import PyTree\n",
    "\n",
    "from netket.operator import (\n",
    "    AbstractOperator,\n",
    "    Squared,\n",
    ")\n",
    "\n",
    "from netket.vqs import expect_and_grad, expect_and_forces\n",
    "from netket.vqs import MCState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the Hilbert space based on this graph\n",
    "# We impose to have a fixed total magnetization of zero\n",
    "# Define a 1d chain\n",
    "L = 4\n",
    "dis = 1\n",
    "g = nk.graph.Hypercube(length=L, n_dim=1, pbc=True)\n",
    "hi = nk.hilbert.Spin(s=0.5, total_sz=0, N=g.n_nodes)\n",
    "# calling the Heisenberg Hamiltonian\n",
    "ha = nk.operator.Heisenberg(hilbert=hi, graph=g)\n",
    "# ha = nk.operator.Heisenberg(hilbert=hi, graph=g)\n",
    "b=dis\n",
    "a=-dis\n",
    "Gamma = (b-a) * np.random.random_sample(L) + a\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "#이렇게 정의하는게 더 빨랑\n",
    "ha = sum([ sigmax(hi,i)*sigmax(hi,(i+1)%L)\n",
    "         + sigmay(hi,i)*sigmay(hi,(i+1)%L)\n",
    "         + sigmaz(hi,i)*sigmaz(hi,(i+1)%L)\n",
    "           for i in range(L)])\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "# ha = ha + sum([Gamma[i]*sigmaz(hi,i) for i in range(L)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc8a9a46610>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E, vec = np.linalg.eigh(ha.to_dense())\n",
    "plt.scatter(range(len(E)),E)\n",
    "# plt.plot([0,len(E)],[Et,Et],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_array(model, parameters):\n",
    "    # begin by generating all configurations in the hilbert space.\n",
    "    # all_States returns a batch of configurations that is (hi.n_states, N) large.\n",
    "    all_configurations = hi.all_states()\n",
    "\n",
    "    # now evaluate the model, and convert to a normalised wavefunction.\n",
    "    logpsi = model.apply(parameters, all_configurations)\n",
    "    psi = jnp.exp(logpsi)\n",
    "    psi = psi / jnp.linalg.norm(psi)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Energy\n",
    "Now, using that function, let's build another one that computes the energy of the mean field state for the given parameters! \n",
    "To do that, you can for example convert the hamiltonian to a sparse format and compute the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_energy(model, parameters, hamiltonian_sparse):\n",
    "    psi_gs = to_array(model, parameters)\n",
    "    return psi_gs.conj().T@(hamiltonian_sparse@psi_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and like before, we can jit-compile it!\n",
    "compute_energy_jit = jax.jit(compute_energy, static_argnames=\"model\")\n",
    "\n",
    "# and we precompute the sparse-hamiltonian to avoid the overhead of re-computing them all the time\n",
    "hamiltonian_jax = ha.to_pauli_strings().to_jax_operator()\n",
    "hamiltonian_sparse = ha.to_sparse()\n",
    "hamiltonian_jax_sparse = hamiltonian_jax.to_sparse()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = nk.models.RBM(alpha=2, param_dtype=complex)\n",
    "key = jax.random.key(0)\n",
    "\n",
    "parameters = model.init(key, np.random.rand(hi.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now rerun the same analysis as before but with this ansatz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo complications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we did everything by summing over the whole hilbert space, but for larger problems that won't be possible. So let's look into MC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_energies(model, parameters, hamiltonian_jax, sigma):\n",
    "    eta, H_sigmaeta = hamiltonian_jax.get_conn_padded(sigma)\n",
    "    \n",
    "    logpsi_sigma = model.apply(parameters, sigma)\n",
    "    logpsi_eta = model.apply(parameters, eta)\n",
    "    logpsi_sigma = jnp.expand_dims(logpsi_sigma, -1) \n",
    "    \n",
    "    res = jnp.sum(H_sigmaeta * jnp.exp(logpsi_eta - logpsi_sigma), axis=-1)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3 Sampling the energy\n",
    "\n",
    "So now write a function that computes the energy and estimates its error. I remind you that the error is given by \n",
    "\n",
    "$$\n",
    "    \\epsilon_E = \\sqrt{\\frac{\\mathbb{V}\\text{ar}(E_\\text{loc})}{N_\\text{samples}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames='model')\n",
    "def estimate_energy(model, parameters, hamiltonian_jax, sigma):\n",
    "    E_loc = compute_local_energies(model, parameters, hamiltonian_jax, sigma)\n",
    "    \n",
    "    E_average = jnp.mean(E_loc)\n",
    "    E_variance = jnp.var(E_loc)\n",
    "    E_error = jnp.sqrt(E_variance / E_loc.size)\n",
    "    \n",
    "    # we return a netket Stats object that wraps all statistical information related to this mean value.\n",
    "    return nk.stats.Stats(mean=E_average, error_of_mean=E_error, variance=E_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4 Sampling the gradient of the energy \n",
    "\n",
    "We have seen during the class that the gradient of the energy can be estimated according to the formula\n",
    "\n",
    "$$\n",
    "    \\nabla_k E = \\mathbb{E}_{\\sigma\\sim|\\psi(\\sigma)|^2} \\left[ (\\nabla_k \\log\\psi(\\sigma))^\\star \\left( E_\\text{loc}(\\sigma) - \\langle E \\rangle\\right)\\right] \\approx \\frac{1}{N_s}\\sum_i^{N_s} (\\nabla_k \\log\\psi(\\sigma_i))^\\star \\left( E_\\text{loc}(\\sigma_i) - \\langle E \\rangle\\right)\n",
    "$$\n",
    "\n",
    "Where $\\langle E \\rangle$ can be estimated as $\\langle E \\rangle \\approx \\frac{1}{N_s}\\sum_i E_\\text{loc}(\\sigma_i)$\n",
    "\n",
    "Now, for a second, think of $\\nabla_k \\log\\psi(\\sigma_i)$ as the _JACOBIAN_ of the function $\\log\\psi_\\sigma : \\mathbb{R}^{N_\\text{pars}} \\rightarrow \\mathbb{R}^{N_\\text{samples}}$, and think for a moment of $E_\\text{loc}(\\sigma_i)$ as a vector of size $\\mathbb{R}^{N_\\text{samples}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a function that computes the jacobian-vector product in order to estimate the gradient of the energy. You can either do this vector-Jacobian-transpose product manually by using `jax.jacrev` and `jax.tree.map`, but you can also have a look at `jax.vjp` which does it automatically for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames='model')\n",
    "def estimate_energy_and_gradient(model, parameters, hamiltonian_jax, sigma):\n",
    "    # reshape the samples to a vector of samples with no extra batch dimensions\n",
    "    sigma = sigma.reshape(-1, sigma.shape[-1])\n",
    "    \n",
    "    E_loc = compute_local_energies(model, parameters, hamiltonian_jax, sigma)\n",
    "    \n",
    "    # compute the energy as well\n",
    "    E_average = jnp.mean(E_loc)\n",
    "    E_variance = jnp.var(E_loc)\n",
    "    E_error = jnp.sqrt(E_variance/E_loc.size)\n",
    "    E = nk.stats.Stats(mean=E_average, error_of_mean=E_error, variance=E_variance)\n",
    "\n",
    "    # comptue the gradient ...\n",
    "    # first define the function to be differentiated\n",
    "    logpsi_sigma_fun = lambda pars : model.apply(pars, sigma)\n",
    "\n",
    "    # use jacrev with jax.tree.map, or even better, jax.vjp\n",
    "    _, vjpfun = jax.vjp(logpsi_sigma_fun, parameters)\n",
    "    E_grad = vjpfun((E_loc - E_average)/E_loc.size)\n",
    "\n",
    "    return E, E_grad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.5: Let's get down to business\n",
    "\n",
    "Now let's wrap everything up and let's use this code to compute the ground state with an SGD optimisation using the mean field and jastrow ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████▎                   | 1444/3000 [00:14<00:15, 100.70it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import optax\n",
    "\n",
    "# settings \n",
    "# model = nk.models.RBM(alpha=2, param_dtype=complex)\n",
    "model = nk.models.RBM(alpha=2, param_dtype=complex)\n",
    "sampler = nk.sampler.MetropolisSampler(\n",
    "                        hi,                            # the hilbert space to be sampled\n",
    "                        nk.sampler.rules.ExchangeRule(graph=g),  # the transition rule\n",
    "                        # nk.sampler.rules.LocalRule(),\n",
    "                        n_chains = 16)\n",
    "n_iters = 3000\n",
    "chain_length = 1024//sampler.n_chains\n",
    "\n",
    "# initialise\n",
    "parameters = model.init(jax.random.key(0), np.ones((hi.size, )))\n",
    "sampler_state = sampler.init_state(model, parameters, seed=1)\n",
    "\n",
    "optimizer = optax.adam(learning_rate=0.001)\n",
    "optimizer_state = optimizer.init(parameters)\n",
    "\n",
    "\n",
    "# logging: you can (if you want) use netket loggers to avoid writing a lot of boilerplate...\n",
    "# they accumulate data you throw at them\n",
    "logger = nk.logging.RuntimeLog()\n",
    "\n",
    "for i in tqdm(range(n_iters)):\n",
    "    # sample\n",
    "    sampler_state = sampler.reset(model, parameters, state=sampler_state)\n",
    "    samples, sampler_state = sampler.sample(model, parameters, state=sampler_state, chain_length=chain_length)\n",
    "    \n",
    "    # compute energy and gradient\n",
    "    E, E_grad = estimate_energy_and_gradient(model, parameters, hamiltonian_jax, samples)\n",
    "    updates, optimizer_state = optimizer.update(E_grad, optimizer_state, parameters)\n",
    "    parameters = optax.apply_updates(parameters, updates)\n",
    "    logger(step=i, item={'Energy' : E})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the data, access it!\n",
    "plt.plot(logger.data['Energy']['iters'], logger.data['Energy']['Mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Try better optimisers\n",
    "\n",
    "There is a library, [optax](https://optax.readthedocs.io/en/latest/), that implements several optimisers. \n",
    "Try to use adam or other optimisers.\n",
    "The way you use them is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "# define\n",
    "optimizer = optax.adam(learning_rate=0.01)\n",
    "\n",
    "# initialise\n",
    "parameters = model.init(...)\n",
    "optimizer_state = optimizer.init(parameters)\n",
    "\n",
    "for i in range(n_iters):\n",
    "    E, E_grad = estimate_energy_and_grad(..., parameters, ...)\n",
    "    \n",
    "    updates, optimizer_state = optimizer.update(E_grad, optimizer_state, parameters)\n",
    "    parameters = optax.apply_updates(parameters, updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Sky's the limit\n",
    "\n",
    "What you've seen so far gives you the tools to quickly get started in running VMC calculations, without having to worry about sampling (which is a bit tricky to implement) and operators (which are very tricky to implement).\n",
    "\n",
    "You can use this as a starting point to implement stochastic reconfiguration, the dynamics, and much more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
