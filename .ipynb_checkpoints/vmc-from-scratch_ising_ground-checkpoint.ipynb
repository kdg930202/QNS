{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netket as nk\n",
    "from numpy.lib.function_base import append\n",
    "from itertools import permutations, combinations\n",
    "from netket.vqs.mc import get_local_kernel_arguments, get_local_kernel\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from flax.core.frozen_dict import FrozenDict\n",
    "import flax\n",
    "from netket.optimizer.qgt import QGTJacobianPyTree\n",
    "\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from netket.stats import statistics as mpi_statistics, mean as mpi_mean, Stats\n",
    "from netket.utils.types import PyTree\n",
    "from netket.operator.spin import sigmax, sigmay,sigmaz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "################################################################\n",
    "from scipy.sparse.linalg import eigsh\n",
    "################################################################\n",
    "import os\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We always shorten netket as nk\n",
    "import netket as nk\n",
    "\n",
    "# Define a 1d chain\n",
    "L = 6\n",
    "g = nk.graph.Hypercube(length=L, n_dim=1, pbc=True)\n",
    "hi = nk.hilbert.Spin(s=1/2, N=g.n_nodes)\n",
    "# hamiltonian = nk.operator.Heisenberg(hilbert=hi, graph=g)\n",
    "# hamiltonian = nk.operator.Ising(h=1.321, hilbert=hi, J=0.5, graph=g)\n",
    "# hamiltonian = sum([ sigmax(hi,i)*sigmax(hi,(i+1)%L)\n",
    "#                        + sigmay(hi,i)*sigmay(hi,(i+1)%L)\n",
    "#                        + sigmaz(hi,i)*sigmaz(hi,(i+1)%L)\n",
    "#                          for i in range(L)])\n",
    "\n",
    "# 1D Ising\n",
    "hamiltonian = sum([sigmaz(hi,i)*sigmaz(hi,(i+1)%L)\n",
    "                         for i in range(L)])\n",
    "\n",
    "\n",
    "#1D Heisenberg\n",
    "# hamiltonian = sum([ \n",
    "#                     sigmax(hi,i)*sigmax(hi,(i+1)%L)\n",
    "#                     +sigmay(hi,i)*sigmay(hi,(i+1)%L) #이 녀석이 자꾸 pauli term을 complex로 만든다......\n",
    "#                     +sigmaz(hi,i)*sigmaz(hi,(i+1)%L)\n",
    "#                          for i in range(L)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0000000000000036"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todelete\n",
    "from scipy.sparse.linalg import eigsh\n",
    "ha = hamiltonian.to_sparse()\n",
    "e_gs, psi_gs = eigsh(ha, k=1)\n",
    "e_gs = e_gs[0]\n",
    "psi_gs = psi_gs.reshape(-1)\n",
    "e_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model itself is only a set of instructions on how to initialise the parameters and how to compute the result. \n",
    "\n",
    "To initialise the parameters we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_array(model, parameters):\n",
    "    # begin by generating all configurations in the hilbert space.\n",
    "    # all_States returns a batch of configurations that is (hi.n_states, N) large.\n",
    "    all_configurations = hi.all_states()\n",
    "\n",
    "    # now evaluate the model, and convert to a normalised wavefunction.\n",
    "    logpsi = model.apply(parameters, all_configurations)\n",
    "    psi = jnp.exp(logpsi)\n",
    "    psi = psi / jnp.linalg.norm(psi)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Energy\n",
    "Now, using that function, let's build another one that computes the energy of the mean field state for the given parameters! \n",
    "To do that, you can for example convert the hamiltonian to a sparse format and compute the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_energy(model, parameters, hamiltonian_sparse):\n",
    "    psi_gs = to_array(model, parameters)\n",
    "    return psi_gs.conj().T@(hamiltonian_sparse@psi_gs)\n",
    "\n",
    "def compute_variance(model, parameters, hamiltonian_sparse):\n",
    "    psi_gs = to_array(model, parameters)\n",
    "    variance = psi_gs.conj().T@(hamiltonian_sparse@hamiltonian_sparse@psi_gs) - (psi_gs.conj().T@(hamiltonian_sparse@psi_gs))**2 \n",
    "    return variance\n",
    "\n",
    "def compute_energy_vjp(parameters):\n",
    "    psi_gs = to_array(model, parameters)\n",
    "    return psi_gs.conj().T@(hamiltonian_jax_sparse@psi_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and like before, we can jit-compile it!\n",
    "compute_energy_jit = jax.jit(compute_energy, static_argnames=\"model\")\n",
    "\n",
    "# and we precompute the sparse-hamiltonian to avoid the overhead of re-computing them all the time\n",
    "hamiltonian_jax = hamiltonian.to_pauli_strings().to_jax_operator()\n",
    "hamiltonian_sparse = hamiltonian.to_sparse()\n",
    "hamiltonian_jax_sparse = hamiltonian_jax.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PauliStringsJax(hilbert=Spin(s=1/2, N=6), n_strings=6, dtype=float64, dict(operators:weights)=\n",
       "    ZZIIII : 1.0,\n",
       "    IZZIII : 1.0,\n",
       "    IIZZII : 1.0,\n",
       "    IIIZZI : 1.0,\n",
       "    IIIIZZ : 1.0,\n",
       "    ZIIIIZ : 1.0\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltonian_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# we use partial to directly jit this function. Jitting the top-most will jit everything inside it as well.\n",
    "@partial(jax.jit, static_argnames='model')\n",
    "def compute_energy_and_gradient(model, parameters, hamiltonian_sparse):\n",
    "    grad_fun = jax.value_and_grad(compute_energy, argnums=1)\n",
    "#     _, grad_fun = jax.vjp(compute_energy_vjp, parameters)\n",
    "    return grad_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▊                            | 2598/10000 [00:44<02:03, 59.72it/s]"
     ]
    }
   ],
   "source": [
    "model = nk.models.RBM(alpha=1)\n",
    "\n",
    "parameters = model.init(jax.random.PRNGKey(0), np.ones((hi.size, )))\n",
    "\n",
    "# logging: you can (if you want) use netket loggers to avoid writing a lot of boilerplate...\n",
    "# they accumulate data you throw at them\n",
    "# logger = nk.logging.RuntimeLog()\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000)):\n",
    "    # compute energy and gradient\n",
    "#     energy, gradient = compute_energy_and_gradient(model, parameters, hamiltonian_jax_sparse)\n",
    "    _, grad_fun = jax.vjp(compute_energy_vjp, parameters)\n",
    "    gradient = grad_fun(1.0)[0]\n",
    "    # update parameters\n",
    "    parameters = jax.tree_map(lambda x,y:x-0.01*y, parameters, gradient)\n",
    "    \n",
    "    # log energy: the logger takes a step argument and a dictionary of variables to be logged\n",
    "    # logger(step=i, item={'Energy':energy})\n",
    "\n",
    "    _, grad_fun = jax.vjp(compute_energy_vjp, parameters)\n",
    "compute_variance(model, parameters, hamiltonian_sparse)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
